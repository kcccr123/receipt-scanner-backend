{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5150a0d-72a0-4aa2-ac4a-61295dc1b220",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BartTokenizer, BartForConditionalGeneration, AdamW\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize_function, TextDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from utils import tokenize_function, TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1167bea-f9f7-4348-bf4c-5c9a263c10ab",
   "metadata": {},
   "source": [
    "## Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff44668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VO FOg^ DEjIIUS\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def misspell(word):\n",
    "    result = word\n",
    "    repeat = 1\n",
    "    if len(word) > 1:\n",
    "        op = random.choice(['rmv', 'rpl'])\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        if op == 'rmv':\n",
    "            result = word[:pos] + word[pos+1:]\n",
    "        elif op == 'rpl':\n",
    "            result = word[:pos] + random.choice(string.ascii_letters) + word[pos+1:]\n",
    "        \n",
    "        if len(word) > 5:\n",
    "            repeat = 3\n",
    "        \n",
    "        i = 0\n",
    "        while i < repeat:\n",
    "            op = random.choice(['rmv', 'rpl'])\n",
    "            pos = random.randint(0, len(word) - 1)\n",
    "            if op == 'rmv':\n",
    "                result = result[:pos] + result[pos+1:]\n",
    "            elif op == 'rpl':\n",
    "                result = result[:pos] + random.choice(string.ascii_letters) + result[pos+1:]\n",
    "            i+=1\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def add_noise(name):\n",
    "    words = name.split()\n",
    "\n",
    "    random.shuffle(words)\n",
    "\n",
    "    noisy_words = []\n",
    "    for word in words:\n",
    "        if random.random() < 0.5:\n",
    "            word = misspell(word)\n",
    "        if random.random() < 0.25:\n",
    "            word = ''.join([word, ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=random.randint(1, 5)))])\n",
    "        noisy_words.append(word)\n",
    "\n",
    "    return ' '.join(noisy_words)\n",
    "\n",
    "valid_name = \"DELICIOUS DOG FOOD\"\n",
    "noisy_text = add_noise(valid_name)\n",
    "print(noisy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a888d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16470\n",
      "123508\n",
      "{'input': 'Economy Themomxtr1rf4, Allegiance#A Dual-scaleY`W DCal', 'output': 'Allegiance Economy Dual-scale Digital Thermometer'}\n",
      "{'input': 'Ei Slalom with FonDFBP)2 Daddy igc Connelly Water8I BankwF*-3', 'output': 'Big Daddy Blank with Fins Connelly Slalom Water Ski'}\n",
      "{'input': 'Girls oleYp Youth*.O Skate Dgry iirear Roller', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}\n",
      "[{'input': 'Girls oleYp Youth*.O Skate Dgry iirear Roller', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}, {'input': 'Sjae Roller Roller Drby Youth Girls FireStar', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}, {'input': 'jkte FireStarPv& Xolxr Loutm erbmHjqR Pamer,4. Girls', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}, {'input': 'Girls FireStar Derby7=~\\\\Z Skate YouzWH Rolh Ioglern', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}, {'input': 'FirSaTy% Rlerf Derbt ollrX0Rs Girls Youth Skate', 'output': 'Roller Derby FireStar Youth Girls Roller Skate'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = r\"D:\\photos\\Words\\walmart\\home\\sdf\\marketing_sample_for_walmart_com-product_details__20200101_20200331__30k_data.csv\"\n",
    "save_dir = r\"D:\\photos\\Words\\walmart\\home\\sdf\"\n",
    "csv = pd.read_csv(csv_path)\n",
    "\n",
    "test = 0\n",
    "\n",
    "data_set = []\n",
    "for i in range(0, csv.shape[0]):\n",
    "    grd_truth = csv.loc[i].at[\"Product Name\"]\n",
    "\n",
    "    if len(grd_truth) < 60 and grd_truth != \"\":\n",
    "        test += 1\n",
    "        variations = 5 + random.choice(range(0,6))\n",
    "        id = 0;\n",
    "        while id < variations:\n",
    "            temp = {}\n",
    "            temp[\"input\"] = add_noise(grd_truth)\n",
    "            temp[\"output\"] = grd_truth\n",
    "            data_set.append(temp)\n",
    "            id += 1\n",
    "\n",
    "print(test)\n",
    "print(len(data_set))\n",
    "print(data_set[1])\n",
    "print(data_set[300])\n",
    "print(data_set[4000])\n",
    "print(data_set[4000:4005])\n",
    "# 22464\n",
    "# 13745\n",
    "# 16470\n",
    "# 18096\n",
    "# 9406 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8257f043-cce7-47f8-bc89-cb732262ca02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSUGGESTIONS:\\n\\nGet a data set of product names. \\nFor example: https://www.kaggle.com/datasets/promptcloud/walmart-product-details-2020/data\\n\\n1. Create a name scrambler function.\\nThis function takes each word in the product name and scrambles both the position in the name and applies a MINOR scramble to the letters\\n\\n2. Loop through product data sets, For each product name\\n- Create multiple data inputs\\n    - product name is output\\n    - scramble the product name multiple times to create multiple inputs\\n\\ni.e for product name: \"Whiskers Cat Food\", you could produce 3 data inputs:\\n{\"input\": \"CST FOOL WHISKERS\", \"output\": \"Whiskers Cat Food\"},\\n{\"input\": \"TAC WISKERS FEEDS\", \"output\": \"Whiskers Cat Food\"},\\n{\"input\": \"WFHSIEKRS CAT FOPD\", \"output\": \"Whiskers Cat Food\"},\\n\\nCreate more than 3 outputs though\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Format of train/val should be:\n",
    "Where each dictionary is a data input, with input and output\n",
    "data = [\n",
    "    {\"input\": \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\", \"output\": \"DELICIOUS DOG FOOD\"},\n",
    "    {\"input\": \"CHCOLATE BAR CACAO 70%\", \"output\": \"CHOCOLATE BAR CACAO 70%\"},\n",
    "    # Add more examples...\n",
    "]\n",
    "'''\n",
    "# FOR GARY\n",
    "# TODO\n",
    "# Take public data set and convert to list of dictionaries (see below for data examples)\n",
    "# data = \n",
    "\n",
    "'''\n",
    "SUGGESTIONS:\n",
    "\n",
    "Get a data set of product names. \n",
    "For example: https://www.kaggle.com/datasets/promptcloud/walmart-product-details-2020/data\n",
    "\n",
    "1. Create a name scrambler function.\n",
    "This function takes each word in the product name and scrambles both the position in the name and applies a MINOR scramble to the letters\n",
    "\n",
    "2. Loop through product data sets, For each product name\n",
    "- Create multiple data inputs\n",
    "    - product name is output\n",
    "    - scramble the product name multiple times to create multiple inputs\n",
    "\n",
    "i.e for product name: \"Whiskers Cat Food\", you could produce 3 data inputs:\n",
    "{\"input\": \"CST FOOL WHISKERS\", \"output\": \"Whiskers Cat Food\"},\n",
    "{\"input\": \"TAC WISKERS FEEDS\", \"output\": \"Whiskers Cat Food\"},\n",
    "{\"input\": \"WFHSIEKRS CAT FOPD\", \"output\": \"Whiskers Cat Food\"},\n",
    "\n",
    "Create more than 3 outputs though\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5cbc78-ee4d-4ac8-b795-b710b43a28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example list\n",
    "data = [\n",
    "    {\"input\": \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\", \"output\": \"DELICIOUS DOG FOOD\"},\n",
    "    {\"input\": \"CHCOLATE BAR CACAO 70%\", \"output\": \"CHOCOLATE BAR CACAO 70%\"},\n",
    "    {\"input\": \"TOMTO SCE KETHCUP\", \"output\": \"TOMATO SAUCE KETCHUP\"},\n",
    "    {\"input\": \"PNAPL JLCE NATURL\", \"output\": \"PINEAPPLE JUICE NATURAL\"},\n",
    "    {\"input\": \"ALMOND MLIK UNSWEETND\", \"output\": \"ALMOND MILK UNSWEETENED\"},\n",
    "    {\"input\": \"PEANUT BTER CRMCHY\", \"output\": \"PEANUT BUTTER CRUNCHY\"},\n",
    "    {\"input\": \"IC CREAM VANILA FLAVOR\", \"output\": \"ICE CREAM VANILLA FLAVOR\"},\n",
    "    {\"input\": \"APPLE SIDER VINIGR\", \"output\": \"APPLE CIDER VINEGAR\"},\n",
    "    {\"input\": \"WHOL WHT BREAD SLICD\", \"output\": \"WHOLE WHEAT BREAD SLICED\"},\n",
    "    {\"input\": \"ORANGE JLCE FRESH SQZD\", \"output\": \"ORANGE JUICE FRESH SQUEEZED\"},\n",
    "    {\"input\": \"GRN TEA OGRNIC\", \"output\": \"GREEN TEA ORGANIC\"},\n",
    "    {\"input\": \"SPGHTTI PASTA WHEAT\", \"output\": \"SPAGHETTI PASTA WHEAT\"},\n",
    "    {\"input\": \"PRCHUTO SLCD\", \"output\": \"PROSCIUTTO SLICED\"},\n",
    "    {\"input\": \"BRCOLI FRSH ORGANIC\", \"output\": \"BROCCOLI FRESH ORGANIC\"},\n",
    "    {\"input\": \"CAROT JCE RAW\", \"output\": \"CARROT JUICE RAW\"},\n",
    "    {\"input\": \"MZN HNY PRSSED\", \"output\": \"MANUKA HONEY PRESSED\"},\n",
    "    {\"input\": \"STRAWBRY YOGRT LITE\", \"output\": \"STRAWBERRY YOGURT LIGHT\"},\n",
    "    {\"input\": \"BLUERRYS FROZN\", \"output\": \"BLUEBERRIES FROZEN\"},\n",
    "    {\"input\": \"SRIRCHA HOT SCE\", \"output\": \"SRIRACHA HOT SAUCE\"},\n",
    "    {\"input\": \"ZUCCHN ORGNIC\", \"output\": \"ZUCCHINI ORGANIC\"},\n",
    "    {\"input\": \"CHCKN BRST BNELESS\", \"output\": \"CHICKEN BREAST BONELESS\"},\n",
    "    {\"input\": \"BTRSCOTCH CHIPS\", \"output\": \"BUTTERSCOTCH CHIPS\"},\n",
    "    {\"input\": \"CRML SCE DIPPING\", \"output\": \"CARAMEL SAUCE DIPPING\"},\n",
    "    {\"input\": \"CCHNUT WTR PURE\", \"output\": \"COCONUT WATER PURE\"},\n",
    "    {\"input\": \"GREEK YOUGRT PLAIN\", \"output\": \"GREEK YOGURT PLAIN\"},\n",
    "    {\"input\": \"WHT CHOCOLATE COOKS\", \"output\": \"WHITE CHOCOLATE COOKIES\"},\n",
    "    {\"input\": \"SHRIMP CRCKERS SPICY\", \"output\": \"SHRIMP CRACKERS SPICY\"},\n",
    "    {\"input\": \"GRN APPLES ORGNC\", \"output\": \"GREEN APPLES ORGANIC\"},\n",
    "    {\"input\": \"RSPBRY JAM HOMEMADE\", \"output\": \"RASPBERRY JAM HOMEMADE\"},\n",
    "    {\"input\": \"PEACH NECTAR CONCENTRTE\", \"output\": \"PEACH NECTAR CONCENTRATE\"},\n",
    "    {\"input\": \"BBY SPINACH FRESH\", \"output\": \"BABY SPINACH FRESH\"},\n",
    "    {\"input\": \"TMATO PASTE ORGNIC\", \"output\": \"TOMATO PASTE ORGANIC\"},\n",
    "    {\"input\": \"GRLIC CLVES CRUSHED\", \"output\": \"GARLIC CLOVES CRUSHED\"},\n",
    "    {\"input\": \"MANGO CHUNKS FROZN\", \"output\": \"MANGO CHUNKS FROZEN\"},\n",
    "    {\"input\": \"HNY DRZZLE ORGANIC\", \"output\": \"HONEY DRIZZLE ORGANIC\"},\n",
    "    {\"input\": \"LITE SPRAY OLIVE OIL\", \"output\": \"LIGHT SPRAY OLIVE OIL\"},\n",
    "    {\"input\": \"CNMON POWDER PURE\", \"output\": \"CINNAMON POWDER PURE\"},\n",
    "    {\"input\": \"BLAC PEPPER WHOLE\", \"output\": \"BLACK PEPPER WHOLE\"},\n",
    "    {\"input\": \"SRIRCHA POWDER SPICY\", \"output\": \"SRIRACHA POWDER SPICY\"},\n",
    "    {\"input\": \"POTATO CHPS CRISPY\", \"output\": \"POTATO CHIPS CRISPY\"},\n",
    "    {\"input\": \"CRN CHPS CHEESY\", \"output\": \"CORN CHIPS CHEESY\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192debb1-3c77-4fbe-a129-409552b0f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc11990-3d85-4464-b70c-22e2f3007983",
   "metadata": {},
   "source": [
    "## Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836b31df-514c-4087-b031-8dfd97a13656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021903b8-4e1a-41c7-8bb8-76bddb52acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokens for each data input\n",
    "# tokenize_function input is (data set input, model tokenizer, and max length of string)\n",
    "tokenized_train = [tokenize_function(i, tokenizer, 32) for i in train]\n",
    "tokenized_val = [tokenize_function(i, tokenizer, 32) for i in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51110f8e-627f-4d1b-bacf-7ecd93c6d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set\n",
    "train_dataset = TextDataset(tokenized_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d4a97c-27c3-40b8-bfbc-9701ffa2da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create val set\n",
    "val_dataset = TextDataset(tokenized_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf8dc7-1d0d-4902-8d96-a3d695967fde",
   "metadata": {},
   "source": [
    "## Run Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9655a7-4e44-44c9-aa5f-26b3af776108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdamW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up optimizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[0;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#set model to training\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AdamW' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "#set model to training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    total_train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Ensure the correct batch structure\n",
    "        print(batch)\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        # Pass the inputs to the model\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Training Loss: {avg_train_loss}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            \n",
    "            # Pass the inputs to the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    # Set the model back to training mode for the next epoch\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ae1e28-0c24-4acc-85e0-ee92aab922eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\n",
      "Final Validation Loss: 1.3210673332214355\n",
      "Final Token-Level Validation Accuracy: 0.7069\n",
      "Final Sentence-Level Validation Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL RESULTS VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "final_val_loss = 0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "correct_sentences = 0\n",
    "total_sentences = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
    "        loss = outputs.loss\n",
    "        final_val_loss += loss.item()\n",
    "\n",
    "        # Get model predictions (greedy decoding)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        # Flatten the tensors for token-level comparison\n",
    "        predictions_flat = predictions.view(-1)\n",
    "        labels_flat = batch[\"labels\"].view(-1)\n",
    "        \n",
    "        # Only consider non-padding tokens (ignore index 0 or whatever your pad token is)\n",
    "        non_padding_mask = labels_flat != tokenizer.pad_token_id\n",
    "        num_correct = (predictions_flat == labels_flat) & non_padding_mask\n",
    "        \n",
    "        correct_predictions += num_correct.sum().item()\n",
    "        total_predictions += non_padding_mask.sum().item()\n",
    "\n",
    "        # Calculate sentence-level accuracy\n",
    "        for i in range(batch[\"input_ids\"].size(0)):\n",
    "            label_sentence = batch[\"labels\"][i][non_padding_mask[i]].tolist()  # Get the label sentence excluding padding\n",
    "            predicted_sentence = predictions[i][non_padding_mask[i]].tolist()  # Get the predicted sentence excluding padding\n",
    "            \n",
    "            if label_sentence == predicted_sentence:\n",
    "                correct_sentences += 1\n",
    "            total_sentences += 1\n",
    "\n",
    "# Average Loss\n",
    "avg_final_val_loss = final_val_loss / len(val_dataloader)\n",
    "print(f\"Final Validation Loss: {avg_final_val_loss}\")\n",
    "\n",
    "# token level accuracy\n",
    "token_level_accuracy = correct_predictions / total_predictions\n",
    "print(f\"Final Token-Level Validation Accuracy: {token_level_accuracy:.4f}\")\n",
    "\n",
    "# sentence level accuracy\n",
    "sentence_level_accuracy = correct_sentences / total_sentences\n",
    "print(f\"Final Sentence-Level Validation Accuracy: {sentence_level_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed3a136-66f7-41f2-9c40-ea73353af2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pt \n",
    "torch.save(model.state_dict(), \"bart.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949e021-a5c0-4060-9cd8-673641d5dc51",
   "metadata": {},
   "source": [
    "## Prediction example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14030b7d-f5f2-412f-8a73-395976cc88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: FOOD AWADAWDWA DOG FOOD\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(\"bart.pt\"))\n",
    "# Example input text for prediction\n",
    "input_text = \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\"\n",
    "\n",
    "# Tokenize the input\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", max_length=32, truncation=True)\n",
    "\n",
    "# Generate prediction\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(input_ids=tokenized_input[\"input_ids\"], attention_mask=tokenized_input[\"attention_mask\"], max_length=32)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_text = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "print(f\"prediction: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7da22a-ac57-42fd-bb5a-4c17deae9175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
