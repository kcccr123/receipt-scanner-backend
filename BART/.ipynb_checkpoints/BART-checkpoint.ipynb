{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5150a0d-72a0-4aa2-ac4a-61295dc1b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "# from utils import tokenize_function, TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1167bea-f9f7-4348-bf4c-5c9a263c10ab",
   "metadata": {},
   "source": [
    "## Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff44668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS 48.38 FOOD ON DOG SALE DELICIOUS ##PRICE:\n",
      "86.05 TOTAL 583923382 ##TOTAL:\n",
      "132.64 SUBTOTAL ##SUBTOTAL:\n",
      "22.5 TOTAL 959185 ##TOTAL:\n",
      "85.2 SUBTOTAL ##SUBTOTAL:\n",
      "172.83 TOTAL ##TOTAL:\n",
      "98.64 SUBTOTAL ##SUBTOTAL:\n",
      "PAY TO 126.93 BALANCE ##TOTAL:\n",
      "SUBTOTAL 46.07 ##SUBTOTAL:\n",
      "TO PAY 934323 178.44 BALANCE ##TOTAL:\n",
      "SUBTOTAL 120.71 ##SUBTOTAL:\n",
      "TOTAL 5283026593 198.12 ##TOTAL:\n",
      "SUBTOTAL 92.14 ##SUBTOTAL:\n",
      "BALANCE HAo\\bfl 166.76 TO PAY 4222733182 ##TOTAL:\n",
      "SUBTOTAL 9452.26 ##SUBTOTAL:\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def misspell(word):\n",
    "    result = word\n",
    "    repeat = 0\n",
    "    if len(word) > 3:\n",
    "        op = random.choice(['rmv', 'rpl'])\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        if op == 'rmv':\n",
    "            result = word[:pos] + word[pos+1:]\n",
    "        elif op == 'rpl':\n",
    "            result = word[:pos] + random.choice(string.ascii_letters) + word[pos+1:]\n",
    "        \n",
    "        if len(word) > 5:\n",
    "            repeat = 1\n",
    "        elif len(word) >= 7:\n",
    "            repeat = 2\n",
    "        \n",
    "        i = 0\n",
    "        while i < repeat:\n",
    "            op = random.choice(['rmv', 'rpl'])\n",
    "            pos = random.randint(0, len(word) - 1)\n",
    "            if op == 'rmv':\n",
    "                result = result[:pos] + result[pos+1:]\n",
    "            elif op == 'rpl':\n",
    "                result = result[:pos] + random.choice(string.ascii_letters) + result[pos+1:]\n",
    "            i+=1\n",
    "        \n",
    "    return result\n",
    "\n",
    "def shorten_word(word):\n",
    "\n",
    "    if len(word) <= 3:\n",
    "        return word\n",
    "    \n",
    "    chars_to_remove = max(1, len(word) // random.randint(3, 4))\n",
    "    \n",
    "    start_index = len(word) // 2 - chars_to_remove // 2\n",
    "    shortened_word = word[:start_index] + word[start_index + chars_to_remove:]\n",
    "    \n",
    "    return shortened_word\n",
    "\n",
    "\n",
    "def add_noise(name, price):\n",
    "    words = name.split()\n",
    "\n",
    "    noisy_words = []\n",
    "    for word in words:\n",
    "        if random.random() <= 0.5:\n",
    "            word = misspell(word)\n",
    "        else:\n",
    "            word = shorten_word(word)\n",
    "        # if random.random() < 0.20:\n",
    "        #     word = ''.join([word, ''.join(random.choices(string.ascii_letters \n",
    "        #                     + string.digits + string.punctuation, k=random.randint(1, 5)))])\n",
    "        noisy_words.append(word)\n",
    "    \n",
    "    #add price\n",
    "    noisy_words.append(price)\n",
    "\n",
    "    random.shuffle(noisy_words)\n",
    "\n",
    "    noisy_words.append(\"##Price:\")\n",
    "\n",
    "    return ' '.join(noisy_words)\n",
    "\n",
    "def add_serial(name, price, trigger = \"##PRICE:\"):\n",
    "    words = name.split()\n",
    "\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if random.random() <= 0.3:\n",
    "            if random.random() > 0.3:\n",
    "                length = random.randint(6, 12)\n",
    "                word = ' '.join([word, ''.join(random.choices(string.digits, k=length))])\n",
    "            else:\n",
    "                length = random.randint(4, 7)\n",
    "                word = ' '.join([word, ''.join(random.choices(string.ascii_letters + string.punctuation, k=length))])\n",
    "        result.append(word)\n",
    "\n",
    "        #add price\n",
    "    result.append(price)\n",
    "\n",
    "    random.shuffle(result)\n",
    "\n",
    "    result.append(trigger)\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "def rand_price(extra=0):\n",
    "    min_price= 0.00\n",
    "    if random.random() < 0.1:\n",
    "        max_price = 9999.99+extra\n",
    "    elif random.random() <= 0.30:\n",
    "        max_price = 300+extra\n",
    "    else:\n",
    "        max_price = 100 +extra\n",
    "    price = round(random.uniform(min_price, max_price), 2)\n",
    "    return price\n",
    "\n",
    "valid_name = \"DELICIOUS DOG FOOD ON SALE THIS\"\n",
    "# valid_name = \"Chicken Breast\"\n",
    "noisy_text = add_serial(valid_name, f\"{rand_price()}\")\n",
    "# add_noise(valid_name, f\"{rand_price()}\")\n",
    "print(noisy_text)\n",
    "\n",
    "def gen_totals(name, price, trigger):\n",
    "    input = add_serial(name, price, trigger=trigger)\n",
    "    return input\n",
    "    \n",
    "print(gen_totals(\"TOTAL\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"TOTAL\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"TOTAL\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"BALANCE TO PAY\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"BALANCE TO PAY\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"TOTAL\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price(100)}\", \"##SUBTOTAL:\"))\n",
    "print(gen_totals(\"BALANCE TO PAY\", f\"{rand_price(100)}\", \"##TOTAL:\"))\n",
    "print(gen_totals(\"SUBTOTAL\", f\"{rand_price()}\", \"##SUBTOTAL:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a888d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling first dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m add_noise(item_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m add_noise(item_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m     28\u001b[0m temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ##Price:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 50\u001b[0m, in \u001b[0;36madd_noise\u001b[1;34m(name, price)\u001b[0m\n\u001b[0;32m     48\u001b[0m noisy_words \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m     51\u001b[0m         word \u001b[38;5;241m=\u001b[39m misspell(word)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = r\"D:\\photos\\Words\\mini.csv\"\n",
    "csv_path2 = r\"D:\\photos\\Words\\food.csv\"\n",
    "csv_path3 = r\"D:\\photos\\Words\\non-food.csv\"\n",
    "save_dir = r\"D:\\photos\\Words\\walmart\\home\\sdf\"\n",
    "csv = pd.read_csv(csv_path)\n",
    "\n",
    "test = 0\n",
    "\n",
    "data_set = []\n",
    "print(\"Pulling first dataset\")\n",
    "for i in range(0, csv.shape[0]):\n",
    "    item_name = csv.loc[i].at[\"Product Name\"]\n",
    "    if len(item_name) < 61 and item_name != \"\":\n",
    "        test += 1\n",
    "        variations = 12 #5 + random.choice(range(0,6))\n",
    "        id = 0;\n",
    "        while id < variations:\n",
    "            temp = {}\n",
    "            price = rand_price()\n",
    "            if(random.random() < 0.5):\n",
    "                input = add_noise(item_name, f\"{price}\")\n",
    "            else:\n",
    "                input = add_noise(item_name, f\"${price}\")\n",
    "            \n",
    "            temp[\"input\"] = input\n",
    "            temp[\"output\"] = f\"{item_name} ##Price:{price}\"\n",
    "            data_set.append(temp)\n",
    "            id += 1\n",
    "\n",
    "print(\"Dataset is now at \" + str(len(data_set)))\n",
    "print(\"Now pulling second dataset\")\n",
    "\n",
    "csv = pd.read_csv(csv_path2)\n",
    "for i in range(0, csv.shape[0]):\n",
    "    item_name = csv.loc[i].at[\"Product Name\"]\n",
    "    if len(item_name) < 61 and item_name != \"\":\n",
    "        test += 1\n",
    "        variations = 12 #5 + random.choice(range(0,6))\n",
    "        id = 0;\n",
    "        while id < variations:\n",
    "            temp = {}\n",
    "            price = rand_price()\n",
    "            if(random.random() < 0.5):\n",
    "                input = add_noise(item_name, f\"{price}\")\n",
    "            else:\n",
    "                input = add_noise(item_name, f\"${price}\")\n",
    "            \n",
    "            temp[\"input\"] = input\n",
    "            temp[\"output\"] = f\"{item_name} ##Price:{price}\"\n",
    "            data_set.append(temp)\n",
    "            id += 1\n",
    "\n",
    "        id = 0\n",
    "        while id < 3:\n",
    "            id += 1\n",
    "            temp = {}\n",
    "            if(random.random() < 0.5):\n",
    "                input = add_serial(item_name, f\"{price}\")\n",
    "            else:\n",
    "                input = add_serial(item_name, f\"${price}\")\n",
    "            temp[\"input\"] = input\n",
    "            temp[\"output\"] = f\"{item_name} ##Price:{price}\"\n",
    "            data_set.append(temp)\n",
    "\n",
    "print(\"Dataset is now at \" + str(len(data_set)))\n",
    "\n",
    "print(\"Adding in Total and Subtotals\")\n",
    "num = 0\n",
    "while num < 370000:\n",
    "    temp = {}\n",
    "    num += 1\n",
    "    price = rand_price(200)\n",
    "    name = random.choice([\"TOTAL\",\"AMOUNT\", \"BALANCE TO PAY\", \"SUBTOTAL\"])\n",
    "    if name == \"SUBTOTAL\":\n",
    "        trigger = \"##SUBTOTAL:\"\n",
    "    else:\n",
    "        trigger = \"##TOTAL:\"\n",
    "\n",
    "    temp[\"input\"] = gen_totals(name, f'{price}', trigger)\n",
    "    temp[\"output\"] = f\"{name} {trigger}{price}\"\n",
    "    data_set.append(temp)\n",
    "\n",
    "print(\"Dataset is now at \" + str(len(data_set)))\n",
    "print(f\"Total parent labels {test}\")\n",
    "# 22464\n",
    "# 13745\n",
    "# 16470\n",
    "# 18096\n",
    "# 9406 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "caa7d210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Digit Allegiane $2.67 Ecomy xhermomKter Dualcale ##Price:', 'output': 'Allegiance Economy Dual-scale Digital Thermometer ##Price:2.67'}\n",
      "{'input': 'STX 500 PadH $14.98 Lacsse Men Shoder Sueon ##Price:', 'output': 'STX Mens Surgeon 500 Lacrosse Shoulder Pads ##Price:14.98'}\n",
      "{'input': 'ArDofr 16M MC Fooall UnBer $49.15 She BLK HIGXLIGHT Mes ##Price:', 'output': 'Under Armour HIGHLIGHT MC Mens Football Shoe BLBK 16M ##Price:49.15'}\n",
      "{'input': 'Coee $50.82 Moha Icd ##Price:', 'output': 'Mocha Iced Coffee ##Price:50.82'}\n",
      "{'input': '$82.47 Como Brekast Tost ##Price:', 'output': 'Breakfast Toast Combo ##Price:82.47'}\n",
      "{'input': 'Famly Glaed Carts, $0.84 Bay ##Price:', 'output': 'Glazed Baby Carrots, Family ##Price:0.84'}\n",
      "{'input': 'Maid 94.2 Kids Lemonade, Cup 764329 Minute 411365743418 ##PRICE:', 'output': 'Minute Maid Lemonade, Kids Cup ##Price:94.2'}\n",
      "{'input': 'Ban Mfin Rain $43.68 Hoey ##Price:', 'output': 'Honey Bran Raisin Muffin ##Price:43.68'}\n",
      "{'input': '$63.75 12 4828504039 Fanta 47380134 fl Peach, 962662 oz ##PRICE:', 'output': 'Fanta Peach, 12 fl oz ##Price:63.75'}\n",
      "{'input': 'MeiZm Chiken $178.94 Cyowddr, Con ##Price:', 'output': 'Chicken Corn Chowder, Medium ##Price:178.94'}\n",
      "{'input': 'AMOUNT 178878 145.65 ##TOTAL:', 'output': 'AMOUNT ##TOTAL:145.65'}\n",
      "{'input': 'TOTAL 857766669979 9079.52 ##TOTAL:', 'output': 'TOTAL ##TOTAL:9079.52'}\n",
      "{'input': 'PAY TO 4403.16 BALANCE ##TOTAL:', 'output': 'BALANCE TO PAY ##TOTAL:4403.16'}\n",
      "{'input': 'TOTAL 61.56 ##TOTAL:', 'output': 'TOTAL ##TOTAL:61.56'}\n",
      "{'input': 'SUBTOTAL 30.66 ##SUBTOTAL:', 'output': 'SUBTOTAL ##SUBTOTAL:30.66'}\n"
     ]
    }
   ],
   "source": [
    "print(data_set[1])\n",
    "print(data_set[300])\n",
    "print(data_set[4000])\n",
    "print(data_set[170437])\n",
    "print(data_set[805000])\n",
    "print(data_set[900070])\n",
    "print(data_set[678934])\n",
    "print(data_set[700434])\n",
    "print(data_set[823400])\n",
    "print(data_set[1003960])\n",
    "print(data_set[1193960])\n",
    "print(data_set[1233960])\n",
    "print(data_set[1303960])\n",
    "print(data_set[1353960])\n",
    "print(data_set[1443960])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8257f043-cce7-47f8-bc89-cb732262ca02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSUGGESTIONS:\\n\\nGet a data set of product names. \\nFor example: https://www.kaggle.com/datasets/promptcloud/walmart-product-details-2020/data\\n\\n1. Create a name scrambler function.\\nThis function takes each word in the product name and scrambles both the position in the name and applies a MINOR scramble to the letters\\n\\n2. Loop through product data sets, For each product name\\n- Create multiple data inputs\\n    - product name is output\\n    - scramble the product name multiple times to create multiple inputs\\n\\ni.e for product name: \"Whiskers Cat Food\", you could produce 3 data inputs:\\n{\"input\": \"CST FOOL WHISKERS\", \"output\": \"Whiskers Cat Food\"},\\n{\"input\": \"TAC WISKERS FEEDS\", \"output\": \"Whiskers Cat Food\"},\\n{\"input\": \"WFHSIEKRS CAT FOPD\", \"output\": \"Whiskers Cat Food\"},\\n\\nCreate more than 3 outputs though\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Format of train/val should be:\n",
    "Where each dictionary is a data input, with input and output\n",
    "data = [\n",
    "    {\"input\": \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\", \"output\": \"DELICIOUS DOG FOOD\"},\n",
    "    {\"input\": \"CHCOLATE BAR CACAO 70%\", \"output\": \"CHOCOLATE BAR CACAO 70%\"},\n",
    "    # Add more examples...\n",
    "]\n",
    "'''\n",
    "# FOR GARY\n",
    "# TODO\n",
    "# Take public data set and convert to list of dictionaries (see below for data examples)\n",
    "# data = \n",
    "\n",
    "'''\n",
    "SUGGESTIONS:\n",
    "\n",
    "Get a data set of product names. \n",
    "For example: https://www.kaggle.com/datasets/promptcloud/walmart-product-details-2020/data\n",
    "\n",
    "1. Create a name scrambler function.\n",
    "This function takes each word in the product name and scrambles both the position in the name and applies a MINOR scramble to the letters\n",
    "\n",
    "2. Loop through product data sets, For each product name\n",
    "- Create multiple data inputs\n",
    "    - product name is output\n",
    "    - scramble the product name multiple times to create multiple inputs\n",
    "\n",
    "i.e for product name: \"Whiskers Cat Food\", you could produce 3 data inputs:\n",
    "{\"input\": \"CST FOOL WHISKERS\", \"output\": \"Whiskers Cat Food\"},\n",
    "{\"input\": \"TAC WISKERS FEEDS\", \"output\": \"Whiskers Cat Food\"},\n",
    "{\"input\": \"WFHSIEKRS CAT FOPD\", \"output\": \"Whiskers Cat Food\"},\n",
    "\n",
    "Create more than 3 outputs though\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5cbc78-ee4d-4ac8-b795-b710b43a28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example list\n",
    "data = [\n",
    "    {\"input\": \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\", \"output\": \"DELICIOUS DOG FOOD\"},\n",
    "    {\"input\": \"CHCOLATE BAR CACAO 70%\", \"output\": \"CHOCOLATE BAR CACAO 70%\"},\n",
    "    {\"input\": \"TOMTO SCE KETHCUP\", \"output\": \"TOMATO SAUCE KETCHUP\"},\n",
    "    {\"input\": \"PNAPL JLCE NATURL\", \"output\": \"PINEAPPLE JUICE NATURAL\"},\n",
    "    {\"input\": \"ALMOND MLIK UNSWEETND\", \"output\": \"ALMOND MILK UNSWEETENED\"},\n",
    "    {\"input\": \"PEANUT BTER CRMCHY\", \"output\": \"PEANUT BUTTER CRUNCHY\"},\n",
    "    {\"input\": \"IC CREAM VANILA FLAVOR\", \"output\": \"ICE CREAM VANILLA FLAVOR\"},\n",
    "    {\"input\": \"APPLE SIDER VINIGR\", \"output\": \"APPLE CIDER VINEGAR\"},\n",
    "    {\"input\": \"WHOL WHT BREAD SLICD\", \"output\": \"WHOLE WHEAT BREAD SLICED\"},\n",
    "    {\"input\": \"ORANGE JLCE FRESH SQZD\", \"output\": \"ORANGE JUICE FRESH SQUEEZED\"},\n",
    "    {\"input\": \"GRN TEA OGRNIC\", \"output\": \"GREEN TEA ORGANIC\"},\n",
    "    {\"input\": \"SPGHTTI PASTA WHEAT\", \"output\": \"SPAGHETTI PASTA WHEAT\"},\n",
    "    {\"input\": \"PRCHUTO SLCD\", \"output\": \"PROSCIUTTO SLICED\"},\n",
    "    {\"input\": \"BRCOLI FRSH ORGANIC\", \"output\": \"BROCCOLI FRESH ORGANIC\"},\n",
    "    {\"input\": \"CAROT JCE RAW\", \"output\": \"CARROT JUICE RAW\"},\n",
    "    {\"input\": \"MZN HNY PRSSED\", \"output\": \"MANUKA HONEY PRESSED\"},\n",
    "    {\"input\": \"STRAWBRY YOGRT LITE\", \"output\": \"STRAWBERRY YOGURT LIGHT\"},\n",
    "    {\"input\": \"BLUERRYS FROZN\", \"output\": \"BLUEBERRIES FROZEN\"},\n",
    "    {\"input\": \"SRIRCHA HOT SCE\", \"output\": \"SRIRACHA HOT SAUCE\"},\n",
    "    {\"input\": \"ZUCCHN ORGNIC\", \"output\": \"ZUCCHINI ORGANIC\"},\n",
    "    {\"input\": \"CHCKN BRST BNELESS\", \"output\": \"CHICKEN BREAST BONELESS\"},\n",
    "    {\"input\": \"BTRSCOTCH CHIPS\", \"output\": \"BUTTERSCOTCH CHIPS\"},\n",
    "    {\"input\": \"CRML SCE DIPPING\", \"output\": \"CARAMEL SAUCE DIPPING\"},\n",
    "    {\"input\": \"CCHNUT WTR PURE\", \"output\": \"COCONUT WATER PURE\"},\n",
    "    {\"input\": \"GREEK YOUGRT PLAIN\", \"output\": \"GREEK YOGURT PLAIN\"},\n",
    "    {\"input\": \"WHT CHOCOLATE COOKS\", \"output\": \"WHITE CHOCOLATE COOKIES\"},\n",
    "    {\"input\": \"SHRIMP CRCKERS SPICY\", \"output\": \"SHRIMP CRACKERS SPICY\"},\n",
    "    {\"input\": \"GRN APPLES ORGNC\", \"output\": \"GREEN APPLES ORGANIC\"},\n",
    "    {\"input\": \"RSPBRY JAM HOMEMADE\", \"output\": \"RASPBERRY JAM HOMEMADE\"},\n",
    "    {\"input\": \"PEACH NECTAR CONCENTRTE\", \"output\": \"PEACH NECTAR CONCENTRATE\"},\n",
    "    {\"input\": \"BBY SPINACH FRESH\", \"output\": \"BABY SPINACH FRESH\"},\n",
    "    {\"input\": \"TMATO PASTE ORGNIC\", \"output\": \"TOMATO PASTE ORGANIC\"},\n",
    "    {\"input\": \"GRLIC CLVES CRUSHED\", \"output\": \"GARLIC CLOVES CRUSHED\"},\n",
    "    {\"input\": \"MANGO CHUNKS FROZN\", \"output\": \"MANGO CHUNKS FROZEN\"},\n",
    "    {\"input\": \"HNY DRZZLE ORGANIC\", \"output\": \"HONEY DRIZZLE ORGANIC\"},\n",
    "    {\"input\": \"LITE SPRAY OLIVE OIL\", \"output\": \"LIGHT SPRAY OLIVE OIL\"},\n",
    "    {\"input\": \"CNMON POWDER PURE\", \"output\": \"CINNAMON POWDER PURE\"},\n",
    "    {\"input\": \"BLAC PEPPER WHOLE\", \"output\": \"BLACK PEPPER WHOLE\"},\n",
    "    {\"input\": \"SRIRCHA POWDER SPICY\", \"output\": \"SRIRACHA POWDER SPICY\"},\n",
    "    {\"input\": \"POTATO CHPS CRISPY\", \"output\": \"POTATO CHIPS CRISPY\"},\n",
    "    {\"input\": \"CRN CHPS CHEESY\", \"output\": \"CORN CHIPS CHEESY\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192debb1-3c77-4fbe-a129-409552b0f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc11990-3d85-4464-b70c-22e2f3007983",
   "metadata": {},
   "source": [
    "## Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836b31df-514c-4087-b031-8dfd97a13656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021903b8-4e1a-41c7-8bb8-76bddb52acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokens for each data input\n",
    "# tokenize_function input is (data set input, model tokenizer, and max length of string)\n",
    "tokenized_train = [tokenize_function(i, tokenizer, 32) for i in train]\n",
    "tokenized_val = [tokenize_function(i, tokenizer, 32) for i in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51110f8e-627f-4d1b-bacf-7ecd93c6d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set\n",
    "train_dataset = TextDataset(tokenized_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d4a97c-27c3-40b8-bfbc-9701ffa2da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create val set\n",
    "val_dataset = TextDataset(tokenized_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf8dc7-1d0d-4902-8d96-a3d695967fde",
   "metadata": {},
   "source": [
    "## Run Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9655a7-4e44-44c9-aa5f-26b3af776108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdamW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up optimizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[0;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#set model to training\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AdamW' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "#set model to training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    total_train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Ensure the correct batch structure\n",
    "        print(batch)\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        # Pass the inputs to the model\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Training Loss: {avg_train_loss}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            \n",
    "            # Pass the inputs to the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    # Set the model back to training mode for the next epoch\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ae1e28-0c24-4acc-85e0-ee92aab922eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\n",
      "Final Validation Loss: 1.3210673332214355\n",
      "Final Token-Level Validation Accuracy: 0.7069\n",
      "Final Sentence-Level Validation Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL RESULTS VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "final_val_loss = 0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "correct_sentences = 0\n",
    "total_sentences = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
    "        loss = outputs.loss\n",
    "        final_val_loss += loss.item()\n",
    "\n",
    "        # Get model predictions (greedy decoding)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        # Flatten the tensors for token-level comparison\n",
    "        predictions_flat = predictions.view(-1)\n",
    "        labels_flat = batch[\"labels\"].view(-1)\n",
    "        \n",
    "        # Only consider non-padding tokens (ignore index 0 or whatever your pad token is)\n",
    "        non_padding_mask = labels_flat != tokenizer.pad_token_id\n",
    "        num_correct = (predictions_flat == labels_flat) & non_padding_mask\n",
    "        \n",
    "        correct_predictions += num_correct.sum().item()\n",
    "        total_predictions += non_padding_mask.sum().item()\n",
    "\n",
    "        # Calculate sentence-level accuracy\n",
    "        for i in range(batch[\"input_ids\"].size(0)):\n",
    "            label_sentence = batch[\"labels\"][i][non_padding_mask[i]].tolist()  # Get the label sentence excluding padding\n",
    "            predicted_sentence = predictions[i][non_padding_mask[i]].tolist()  # Get the predicted sentence excluding padding\n",
    "            \n",
    "            if label_sentence == predicted_sentence:\n",
    "                correct_sentences += 1\n",
    "            total_sentences += 1\n",
    "\n",
    "# Average Loss\n",
    "avg_final_val_loss = final_val_loss / len(val_dataloader)\n",
    "print(f\"Final Validation Loss: {avg_final_val_loss}\")\n",
    "\n",
    "# token level accuracy\n",
    "token_level_accuracy = correct_predictions / total_predictions\n",
    "print(f\"Final Token-Level Validation Accuracy: {token_level_accuracy:.4f}\")\n",
    "\n",
    "# sentence level accuracy\n",
    "sentence_level_accuracy = correct_sentences / total_sentences\n",
    "print(f\"Final Sentence-Level Validation Accuracy: {sentence_level_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed3a136-66f7-41f2-9c40-ea73353af2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pt \n",
    "torch.save(model.state_dict(), \"bart.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949e021-a5c0-4060-9cd8-673641d5dc51",
   "metadata": {},
   "source": [
    "## Prediction example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14030b7d-f5f2-412f-8a73-395976cc88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: FOOD AWADAWDWA DOG FOOD\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "# load weights\n",
    "model.load_state_dict(torch.load(\"bart.pt\"))\n",
    "# Example input text for prediction\n",
    "input_text = \"FOOD AWADAWDWA DOG 1FD@#$ RUTROW DEIXIOUS\"\n",
    "\n",
    "# Tokenize the input\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", max_length=32, truncation=True)\n",
    "\n",
    "# Generate prediction\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(input_ids=tokenized_input[\"input_ids\"], attention_mask=tokenized_input[\"attention_mask\"], max_length=32)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_text = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "print(f\"prediction: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7da22a-ac57-42fd-bb5a-4c17deae9175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
