{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc41133-843f-4aa9-940d-c114f0e508db",
   "metadata": {},
   "source": [
    "## Install and import depdencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18d81f-c8ae-4641-8927-98a6a6fb1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75ad27-67c4-4bb3-9373-2fa73a99cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install ultralytics\n",
    "!pip install --upgrade ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da25ee3-8d68-4dd6-9355-327a362f12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c6402-5715-4b85-9742-2f0b631a508b",
   "metadata": {},
   "source": [
    "## Prep training materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe251a3a-4ba7-4199-9567-daa167dec175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa9ac0-c67e-4375-8da4-d2c8888de5d7",
   "metadata": {},
   "source": [
    "Please make sure all images are labeled using YOLO format.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Create a folder named \"data\" OUTSIDE of the local repo. This folder will contain all your data.\n",
    "2. Create a subdirectory inside the data folder and add one folder named \"unsplit\". Add your images and labels folders to this subdirectory.\n",
    "   I have included an exmaple directory inside the RSYOLOV8 folder. This is how your data folder should be set up before running the next part of the code.\n",
    "3. Please go into the config.yaml file and set the \"path\" variable to the ABSOLUTE PATH of the data folder.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b426527-49c4-4e15-ac05-c7e329223644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data folder below as well.\n",
    "data_dir = \"D:/RecieptScanner\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50af167-bb66-439e-93bd-06c575458876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "unsplit_dir = os.path.join(data_dir, 'unsplit')\n",
    "images_dir = os.path.join(unsplit_dir, 'images')\n",
    "labels_dir = os.path.join(unsplit_dir, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbdb47-78fa-40e4-8bac-909e2b4ebd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New directories\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc083c0-0e93-4fcc-8f19-3f4f0dc66680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directories\n",
    "for split_dir in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(os.path.join(split_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_dir, 'labels'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896c969-27ac-4c64-84e1-a7c97dfa4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.89\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd444d-bcfe-4f76-9b12-e4c17284d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unsplit images and labels\n",
    "images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "labels = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5189b19-9598-41ef-afac-81f34290e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there is a label for each image\n",
    "images = [img for img in images if f'{os.path.splitext(img)[0]}.txt' in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95dba9-762d-42ad-9e19-057bce2198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392fbe9c-f5ef-4a94-96b9-375e82ca6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate split sizes\n",
    "total_images = len(images)\n",
    "train_size = int(total_images * train_ratio)\n",
    "val_size = int(total_images * val_ratio)\n",
    "test_size = total_images - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc638f-6bda-4041-8932-235cd5a9f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images and labels\n",
    "train_images = images[:train_size]\n",
    "val_images = images[train_size:train_size + val_size]\n",
    "test_images = images[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a86478-75d7-4726-951e-e814d3d00844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move files to appropriate directories\n",
    "def move_files(file_list, source_img_dir, source_lbl_dir, target_dir):\n",
    "    for file_name in file_list:\n",
    "        img_source_path = os.path.join(source_img_dir, file_name)\n",
    "        lbl_source_path = os.path.join(source_lbl_dir, f'{os.path.splitext(file_name)[0]}.txt')\n",
    "        \n",
    "        img_target_path = os.path.join(target_dir, 'images', file_name)\n",
    "        lbl_target_path = os.path.join(target_dir, 'labels', f'{os.path.splitext(file_name)[0]}.txt')\n",
    "        \n",
    "        shutil.copy(img_source_path, img_target_path)\n",
    "        shutil.copy(lbl_source_path, lbl_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b936da-ebdc-492d-962c-ad96838b1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files to train, val, test directories\n",
    "move_files(train_images, images_dir, labels_dir, train_dir)\n",
    "move_files(val_images, images_dir, labels_dir, val_dir)\n",
    "move_files(test_images, images_dir, labels_dir, test_dir)\n",
    "\n",
    "# You are now ready to train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3e9a4-fa6b-4a34-a069-c67f8fcebddc",
   "metadata": {},
   "source": [
    "## Select model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ab775-88e5-468e-b668-70fa1d712351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')  # 'yolov8n.yaml' for untrained or 'yolov8s.pt' for pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c1440-3a4e-413e-8841-82d1c0c72a82",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2430c5-dff0-45e6-9613-95b49cfa61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: Specifies the path to the dataset configuration file\n",
    "# imgsz: Sets the image size\n",
    "# batch: Sets the batch size\n",
    "# epochs: Sets the number of epochs\n",
    "# workers: Sets the number of data loader workers ( i have no idea what this does )\n",
    "#model.train(data='config.yaml', workers=2, iou=0.5, \n",
    "#    epochs=1000, batch= 16, imgsz=640, optimizer='SGD', weight_decay=0.0005, momentum=0.9,)\n",
    "model.train(data=\"config.yaml\", epochs=500, workers=2)\n",
    "# model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0388f-7c35-40b2-a33f-c4a8d03db1e6",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcba4a-e16e-4908-9e05-ac6d4fdb860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4332cfc-da19-4d11-a9aa-621b608dd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute path\n",
    "%matplotlib inline\n",
    "model = YOLO('D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/bestonnx.pt')\n",
    "img = cv2.imread('D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/images/reciept.jpg')\n",
    "results = model(img, conf=0.4, iou=0.4)\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    \n",
    "    # convert into cv2 rectangle\n",
    "    for xyxy in boxes.xyxy:\n",
    "        print(xyxy, \"hellO\")\n",
    "annotated_img = results[0].plot()\n",
    "# Save the annotated image\n",
    "if os.path.exists('annotated_image.jpg'):\n",
    "        os.remove('annotated_image.jpg')\n",
    "cv2.imwrite('annotated_image.jpg', results[0].plot())\n",
    "\n",
    "# Load and display the saved image using matplotlib\n",
    "plt.figure()\n",
    "annotated_img = cv2.imread('annotated_image.jpg')\n",
    "plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Annotated Image with Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19a79a-b8a3-44be-b545-95c7473fc913",
   "metadata": {},
   "source": [
    "## Onnx test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372fa37-f839-40a9-a7da-694f021bec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba0799-db55-45a7-81cd-478eee0fb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Running prediction on ONNX using method 1 (javascript similarity)\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_resized = image.resize(target_size, Image.LANCZOS)\n",
    "    image_array = np.array(image_resized) / 255.0\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array = np.transpose(image_array, (0, 3, 1, 2))\n",
    "    return image_array.astype(np.float32), image\n",
    "\n",
    "def run_onnx_model(model_path, image_array):\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    result = session.run([output_name], {input_name: image_array})\n",
    "    return result\n",
    "\n",
    "def onnx_nms(output, image_size):\n",
    "    num_detections = 8400\n",
    "    output_tensor = output.flatten()\n",
    "    output_array = output_tensor.tolist()\n",
    "\n",
    "    tf_boxes = []\n",
    "    scores = []\n",
    "    classes = []\n",
    "\n",
    "    for i in range(num_detections):\n",
    "        offset = i * 7\n",
    "        classes_scores = output_array[offset + 4: offset + 7]\n",
    "        max_score = max(classes_scores)\n",
    "        max_class_index = classes_scores.index(max_score)\n",
    "\n",
    "        if max_score >= 0.25:\n",
    "            box = [\n",
    "                output_array[offset] - 0.5 * output_array[offset + 2], # x\n",
    "                output_array[offset + 1] - 0.5 * output_array[offset + 3], # y\n",
    "                output_array[offset + 2], # width\n",
    "                output_array[offset + 3], # height\n",
    "            ]\n",
    "\n",
    "            tf_boxes.append(box)\n",
    "            scores.append(max_score)\n",
    "            classes.append(max_class_index)\n",
    "\n",
    "    max_output_size = 100\n",
    "    iou_threshold = 0.1\n",
    "    score_threshold = 400.0\n",
    "\n",
    "    tf_boxes_tensor = tf.convert_to_tensor(tf_boxes)\n",
    "    scores_tensor = tf.convert_to_tensor(scores)\n",
    "    \n",
    "    selected_indices = tf.image.non_max_suppression(\n",
    "        tf_boxes_tensor, scores_tensor, max_output_size, iou_threshold, score_threshold\n",
    "    )\n",
    "\n",
    "    nms_boxes = []\n",
    "    for index in selected_indices.numpy():\n",
    "        nms_boxes.append({\n",
    "            'bbox': tf_boxes[index],\n",
    "            'score': scores[index],\n",
    "            'class': classes[index]\n",
    "        })\n",
    "    print(nms_boxes)\n",
    "    print(len(nms_boxes))\n",
    "    return nms_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, bounding_boxes):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for bbox in bounding_boxes:\n",
    "        box = bbox['bbox']\n",
    "        draw.rectangle([(box[0], box[1]), (box[0] + box[2], box[1] + box[3])], outline=\"red\", width=2)\n",
    "        draw.text((box[0], box[1]), f\"Class: {bbox['class']} Score: {bbox['score']:.2f}\", fill=\"red\")\n",
    "    return image\n",
    "\n",
    "def main(image_path, model_path, target_size):\n",
    "    preprocessed_image, original_image = preprocess_image(image_path, target_size)\n",
    "    model_output = run_onnx_model(model_path, preprocessed_image)\n",
    "    detection_results = onnx_nms(model_output[0], original_image.size)\n",
    "\n",
    "    image_with_boxes = draw_bounding_boxes(original_image, detection_results)\n",
    "    plt.imshow(image_with_boxes)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/images/reciept.jpg'\n",
    "model_path = 'D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/bestonnx.onnx'\n",
    "target_size = (640, 640)\n",
    "\n",
    "main(image_path, model_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec85d7-d73a-4cd1-a9b0-15ba38b30873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# GPT Procedure\n",
    "\n",
    "# Function to perform Non-Maximum Suppression\n",
    "def non_max_suppression(prediction, conf_thresh=0.4, iou_thresh=0.1):\n",
    "    boxes = prediction[:, :4]  # Extract bounding boxes\n",
    "    scores = prediction[:, 4] * prediction[:, 5]  # Compute scores\n",
    "    classes = prediction[:, 6]  # Extract class ids\n",
    "\n",
    "    # Convert boxes to corner coordinates\n",
    "    boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "    boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "\n",
    "    # Apply score threshold\n",
    "    indices = scores > conf_thresh\n",
    "    boxes, scores, classes = boxes[indices], scores[indices], classes[indices]\n",
    "\n",
    "    # Apply NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), conf_thresh, iou_thresh)\n",
    "    if len(indices) > 0:\n",
    "        indices = indices.flatten()\n",
    "        boxes, scores, classes = boxes[indices], scores[indices], classes[indices]\n",
    "\n",
    "    return boxes, scores, classes\n",
    "\n",
    "# Function to draw bounding boxes on an image\n",
    "def draw_bounding_boxes(image, bounding_boxes):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for bbox in bounding_boxes:\n",
    "        box = bbox['bbox']\n",
    "        draw.rectangle([(box[0], box[1]), (box[0] + box[2], box[1] + box[3])], outline=\"red\", width=2)\n",
    "        draw.text((box[0], box[1]), f\"Class: {bbox['class']} Score: {bbox['score']:.2f}\", fill=\"red\")\n",
    "    return image\n",
    "\n",
    "# Main function to run inference\n",
    "def main(image_path, model_path, target_size):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_resized = image.resize(target_size)\n",
    "    image_np = np.array(image_resized).astype(np.float32)\n",
    "    image_np = np.transpose(image_np, (2, 0, 1))  # Change to (C, H, W) format\n",
    "    image_np = np.expand_dims(image_np, axis=0)  # Add batch dimension\n",
    "    image_np /= 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Load the ONNX model\n",
    "    ort_session = ort.InferenceSession(model_path)\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = ort_session.run(None, {ort_session.get_inputs()[0].name: image_np})\n",
    "\n",
    "    # Apply NMS\n",
    "    prediction = outputs[0].reshape(-1, 7)  # Reshape to (8400, 7)\n",
    "    boxes, scores, classes = non_max_suppression(prediction)\n",
    "\n",
    "    # Prepare bounding boxes for drawing\n",
    "    bounding_boxes = [{'bbox': [box[0], box[1], box[2] - box[0], box[3] - box[1]], 'class': int(cls), 'score': score}\n",
    "                      for box, cls, score in zip(boxes, classes, scores)]\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    result_image = draw_bounding_boxes(image, bounding_boxes)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/images/reciept.jpg'\n",
    "model_path = 'D:/RecieptScanner/reciept-scanner/RSYOLOV8/testModels/bestonnx.onnx'\n",
    "target_size = (640, 640)\n",
    "\n",
    "result_image = main(image_path, model_path, target_size)\n",
    "result_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efecba9-3b99-4520-9d86-d9c97aa5959b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299eadb-b24a-473f-99b1-2d5c79f2079f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8",
   "language": "python",
   "name": "yolov8env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
